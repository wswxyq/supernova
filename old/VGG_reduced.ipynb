{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from os import listdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ['./fd-1kpc-9.6sm-0-overlaid.csv/npy0_reduced/', 'fd-1kpc-9.6sm-0-overlaid.csv/bkg_reduced_0']\n",
    "file_list = []\n",
    "for path_ in data_path:\n",
    "    for file_ in listdir(path_):\n",
    "        file_list.append(os.path.join(path_, file_))\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748\n",
      "2252\n"
     ]
    }
   ],
   "source": [
    "siglist=[]\n",
    "for items in file_list:\n",
    "    data = np.load( items )\n",
    "    siglist.append(data['sig'])\n",
    "\n",
    "sigindex=np.array(file_list, dtype='U')[np.array(siglist, dtype=int)==1]\n",
    "bkgindex=np.array(file_list, dtype='U')[np.array(siglist, dtype=int)==0]\n",
    "print(len(sigindex))\n",
    "print(len(bkgindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_list_):\n",
    "        self.file_list = file_list_\n",
    "        self.len = len(file_list_)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.file_list[index]\n",
    "        data = np.load( file_name ) \n",
    "        return torch.from_numpy(data['imxz'][None, :, :]).to(torch.float)/4096, torch.from_numpy(data['imyz'][None, :, :]).to(torch.float)/4096, torch.from_numpy(data['sig']).to(torch.long)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "mydataset = MyDataset(file_list)\n",
    "batch_size_train = 4\n",
    "batch_size_test = 2\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(mydataset))\n",
    "test_size = len(mydataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(mydataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train,\n",
    "                                            shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test,\n",
    "                                            shuffle=False)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(1, 64, 3) \n",
    "        self.conv1_2 = nn.Conv2d(1, 64, 3) \n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv2_2 = nn.Conv2d(64, 128, 3)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3)\n",
    "        self.conv3_2 = nn.Conv2d(128, 256, 3) \n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(256, 256, 3)\n",
    "        self.conv4_2 = nn.Conv2d(256, 256, 3)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(256, 512, 3)\n",
    "        self.conv5_2 = nn.Conv2d(256, 512, 3)\n",
    "\n",
    "        self.conv6_1 = nn.Conv2d(512, 512, 3)\n",
    "        self.conv6_2 = nn.Conv2d(512, 512, 3)\n",
    "\n",
    "        self.conv7_1 = nn.Conv2d(512, 512, 3)\n",
    "        self.conv7_2 = nn.Conv2d(512, 512, 3)\n",
    "\n",
    "        self.conv8_1 = nn.Conv2d(512, 512, 3)\n",
    "        self.conv8_2 = nn.Conv2d(512, 512, 3)\n",
    "\n",
    "        self.fc1_1 = nn.Linear(512 * 11 * 9, 1024)\n",
    "        self.fc1_2 = nn.Linear(512 * 11 * 9, 1024)\n",
    "\n",
    "        self.fc2_1 = nn.Linear(1024, 1024)\n",
    "        self.fc2_2 = nn.Linear(1024, 1024)\n",
    "\n",
    "        self.fc3_1 = nn.Linear(1024, 10)\n",
    "        self.fc3_2 = nn.Linear(1024, 10)\n",
    "\n",
    "        self.fc2= nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1, x2 shape: (896, 384)      channel = 1\n",
    "        x1 = self.pool(F.relu(self.conv1_1(x1)))    # shape: (448, 384)->(446, 382)->(223, 191)\n",
    "\n",
    "        x1 = self.pool(F.relu(self.conv2_1(x1)))    # shape: (223, 191)->(221, 189)->(111, 95)\n",
    "\n",
    "        x1 = F.relu(self.conv3_1(x1))               # shape: (111, 95)->(109, 93)\n",
    "        x1 = self.pool(F.relu(self.conv4_1(x1)))    # shape: (109, 93)->(107, 91)->(54, 46)\n",
    "\n",
    "        x1 = F.relu(self.conv5_1(x1))               # shape: (54, 46)->(52, 44)\n",
    "        x1 = self.pool(F.relu(self.conv6_1(x1)))    # shape: (52, 44)->(50, 42)->(25, 21)\n",
    "\n",
    "        x1 = F.relu(self.conv7_1(x1))               # shape: (25, 21)->(23, 19)\n",
    "        x1 = self.pool(F.relu(self.conv8_1(x1)))    # shape: (23, 19)->(21, 17)->(11, 9)\n",
    "\n",
    "        x1 = torch.flatten(x1, 1) # flatten all dimensions except batch \n",
    "        x1 = F.relu(self.fc1_1(x1))\n",
    "        x1 = F.relu(self.fc2_1(x1))\n",
    "        x1 = self.fc3_1(x1)\n",
    "\n",
    "        x2 = self.pool(F.relu(self.conv1_2(x2)))    # shape: (448, 384)->(446, 382)->(223, 191)\n",
    "        \n",
    "        x2 = self.pool(F.relu(self.conv2_2(x2)))    # shape: (223, 191)->(221, 189)->(111, 95)\n",
    "\n",
    "        x2 = F.relu(self.conv3_2(x2))               # shape: (111, 95)->(109, 93)\n",
    "        x2 = self.pool(F.relu(self.conv4_2(x2)))    # shape: (109, 93)->(107, 91)->(54, 46)\n",
    "\n",
    "        x2 = F.relu(self.conv5_2(x2))               # shape: (54, 46)->(52, 44)\n",
    "        x2 = self.pool(F.relu(self.conv6_2(x2)))    # shape: (52, 44)->(50, 42)->(25, 21)\n",
    "\n",
    "        x2 = F.relu(self.conv7_2(x2))               # shape: (25, 21)->(23, 19)\n",
    "        x2 = self.pool(F.relu(self.conv8_2(x2)))    # shape: (23, 19)->(21, 17)->(11, 9)\n",
    "\n",
    "        x2 = torch.flatten(x2, 1) # flatten all dimensions except batch\n",
    "        x2 = F.relu(self.fc1_2(x2))\n",
    "        x2 = F.relu(self.fc2_2(x2))\n",
    "        x2 = self.fc3_2(x2)\n",
    "\n",
    "\n",
    "        return self.fc2(torch.cat((x1, x2), 1))\n",
    "net=Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1., 1.]).cuda())\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124369470"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 Ti'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch: 0 Loss: 2.5030\n",
      "Epoch: 0, batch: 1 Loss: 2.4742\n",
      "Epoch: 0, batch: 2 Loss: 0.6959\n",
      "Epoch: 0, batch: 3 Loss: 2.3588\n",
      "Epoch: 0, batch: 4 Loss: 0.5791\n",
      "Epoch: 0, batch: 5 Loss: 1.0533\n",
      "Epoch: 0, batch: 6 Loss: 2.7084\n",
      "Epoch: 0, batch: 7 Loss: 2.9833\n",
      "Epoch: 0, batch: 8 Loss: 0.5950\n",
      "Epoch: 0, batch: 9 Loss: 1.0379\n",
      "Epoch: 0, batch: 10 Loss: 1.4091\n",
      "Epoch: 0, batch: 11 Loss: 1.3424\n",
      "Epoch: 0, batch: 12 Loss: 1.0115\n",
      "Epoch: 0, batch: 13 Loss: 0.7234\n",
      "Epoch: 0, batch: 14 Loss: 0.9022\n",
      "Epoch: 0, batch: 15 Loss: 1.0802\n",
      "Epoch: 0, batch: 16 Loss: 0.9657\n",
      "Epoch: 0, batch: 17 Loss: 0.6958\n",
      "Epoch: 0, batch: 18 Loss: 0.6112\n",
      "Epoch: 0, batch: 19 Loss: 0.5636\n",
      "Epoch: 0, batch: 20 Loss: 0.5744\n",
      "Epoch: 0, batch: 21 Loss: 1.0604\n",
      "Epoch: 0, batch: 22 Loss: 1.0808\n",
      "Epoch: 0, batch: 23 Loss: 0.5922\n",
      "Epoch: 0, batch: 24 Loss: 0.2064\n",
      "Epoch: 0, batch: 25 Loss: 0.9123\n",
      "Epoch: 0, batch: 26 Loss: 0.5624\n",
      "Epoch: 0, batch: 27 Loss: 0.7911\n",
      "Epoch: 0, batch: 28 Loss: 0.8839\n",
      "Epoch: 0, batch: 29 Loss: 0.7237\n",
      "Epoch: 0, batch: 30 Loss: 0.7202\n",
      "Epoch: 0, batch: 31 Loss: 0.7985\n",
      "Epoch: 0, batch: 32 Loss: 0.8656\n",
      "Epoch: 0, batch: 33 Loss: 0.8798\n",
      "Epoch: 0, batch: 34 Loss: 0.8414\n",
      "Epoch: 0, batch: 35 Loss: 1.2000\n",
      "Epoch: 0, batch: 36 Loss: 0.7796\n",
      "Epoch: 0, batch: 37 Loss: 0.6990\n",
      "Epoch: 0, batch: 38 Loss: 0.5895\n",
      "Epoch: 0, batch: 39 Loss: 0.7835\n",
      "Epoch: 0, batch: 40 Loss: 0.5631\n",
      "Epoch: 0, batch: 41 Loss: 0.8374\n",
      "Epoch: 0, batch: 42 Loss: 0.8323\n",
      "Epoch: 0, batch: 43 Loss: 0.3252\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7612c7239834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m#print(\"Epoch: {}, batch: {} Loss: {} label_loss:{}\".format(i, batch_idx, loss, label_loss_))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch: {}, batch: {} Loss: {:0.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# begin testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "loss_list = []\n",
    "alpha=0.2\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    net.train()\n",
    "    for (batch_idx, batch) in enumerate(trainloader):\n",
    "        XZ_train_batch = batch[0].cuda() # remove .cuda() if you don't have a GPU\n",
    "        YZ_train_batch = batch[1].cuda() # remove .cuda() if you don't have a GPU\n",
    "        sig_train_batch = batch[2].cuda() # remove .cuda() if you don't have a GPU\n",
    "\n",
    "        Netout = net.forward(XZ_train_batch, YZ_train_batch) # This will call the forward function, usually it returns tensors.\n",
    "        #print(F.softmax(Netout))\n",
    "        loss = criterion(Netout, sig_train_batch) # classification loss\n",
    "\n",
    "        \n",
    "        \n",
    "        # Zero the gradients before running the backward pass.\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "        # parameters of the model. Internally, the parameters of each Module are stored\n",
    "        # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "        # all learnable parameters in the model.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        if batch_idx % 50 == 0 or True:\n",
    "            #print(\"Epoch: {}, batch: {} Loss: {} label_loss:{}\".format(i, batch_idx, loss, label_loss_))\n",
    "            print(\"Epoch: {}, batch: {} Loss: {:0.4f}\".format(i, batch_idx, loss))\n",
    "    \n",
    "    net.eval() # begin testing\n",
    "    preds = np.array([])\n",
    "    reals = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (batch_idx, batch) in enumerate(testloader):\n",
    "            XZ_test_batch = batch[0].cuda() # remove .cuda() if you don't have a GPU\n",
    "            YZ_test_batch = batch[1].cuda() # remove .cuda() if you don't have a GPU\n",
    "            sig_test_batch = batch[2].cuda() # remove .cuda() if you don't have a GPU\n",
    "\n",
    "            Netout = net.forward(XZ_test_batch, YZ_test_batch) # This will call the forward function, usually it returns tensors.\n",
    "            #print(Netout.shape)\n",
    "            prediction=F.softmax(Netout, dim=1).argmax(dim=1)\n",
    "            \n",
    "\n",
    "            preds=np.concatenate((preds, prediction.cpu().detach().numpy().flatten()))\n",
    "            reals=np.concatenate((reals, sig_test_batch.cpu().detach().numpy().flatten()))\n",
    "        preds=np.array(preds)\n",
    "        reals=np.array(reals)\n",
    "        accuracy=np.mean(preds==reals)\n",
    "        accuracy_list.append(accuracy)\n",
    "        print(\"Test accuracy: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siglist=[]\n",
    "for items in file_list:\n",
    "    data = np.load( os.path.join( data_path, items ) )\n",
    "    siglist.append([items, data['sig']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n",
      "tensor([[ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103],\n",
      "        [ 0.5374436975, -0.2166438103]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-374f9e5641ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mNetout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXZ_test_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYZ_test_batch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# This will call the forward function, usually it returns tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNetout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNetout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#print(predictor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# All strings are unicode in Python 3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m    379\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    # Prediction\n",
    "    preds = []\n",
    "    reals = []\n",
    "\n",
    "    for (batch_idx, batch) in enumerate(trainloader):\n",
    "        XZ_test_batch = batch[0].cuda() # remove .cuda() if you don't have a GPU\n",
    "        YZ_test_batch = batch[1].cuda() # remove .cuda() if you don't have a GPU\n",
    "        sig_test_batch = batch[2].cuda() # remove .cuda() if you don't have a GPU\n",
    "\n",
    "        Netout = net.forward(XZ_test_batch, YZ_test_batch) # This will call the forward function, usually it returns tensors.\n",
    "        print(Netout)\n",
    "        prediction=F.softmax(Netout, dim=1).argmax(dim=1)\n",
    "        #print(predictor)\n",
    "\n",
    "        preds.append(prediction.cpu().detach().numpy())\n",
    "        \n",
    "        reals.append(sig_test_batch.cpu().detach().numpy())\n",
    "    preds=np.array(preds)\n",
    "    reals=np.array(reals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(reals.flatten(), preds.flatten()), index = ['background', 'signal'],\n",
    "                  columns = ['background', 'signal'])\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "sn.heatmap(df_cm, annot=True, cmap=\"jet\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label being i-th class and predicted label being j-th class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(reals.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './model_save_train_VGG_reduced.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./model_save_train_VGG_reduced.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 45,  12],\n",
       "       [  8, 335]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(reals.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e343a66b0d3f3fb9e5b3006acd45e89d57a985b4e0912ddff9600a29bb2e852"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
